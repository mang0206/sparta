###
POST http://localhost:8080/v1/chat/completions
Content-Type: application/json

{
  "model": "ollama",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "안녕하세요!"}
  ],
  "temperature": 0.7,
  "max_tokens": 500,
  "stream": false
}
###
POST http://localhost:8081/v1/chat/completions
Content-Type: text/event-stream

{
  "model": "qwen3",
  "messages": [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "!"}
  ],
  "temperature": 0.7,
  "max_tokens": 500,
  "stream": true
}
